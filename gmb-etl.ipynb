{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import yaml\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET DATASET FROM RAVE\n"
     ]
    }
   ],
   "source": [
    "######GET DATASET FROM RAVE######\n",
    "print('GET DATASET FROM RAVE')\n",
    "auth = 'auth_gmb.yaml'\n",
    "with open(auth) as f:\n",
    "    auth = yaml.load(f, Loader = yaml.FullLoader)\n",
    "r = requests.get(auth['API'], auth = HTTPBasicAuth(auth['USERNAME'], auth['PASSWORD']))\n",
    "data_set = r.content.decode(\"utf-8\")\n",
    "data = BeautifulSoup(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORM DATASET\n"
     ]
    }
   ],
   "source": [
    "######TRANSFORM DATASET######\n",
    "print('TRANSFORM DATASET')\n",
    "data_dict = {}\n",
    "for clinicaldata in data.odm:\n",
    "    node_name = clinicaldata.subjectdata.studyeventdata.formdata['formoid']\n",
    "    for itemdata in clinicaldata.subjectdata.studyeventdata.formdata.itemgroupdata:\n",
    "        if node_name not in data_dict.keys():\n",
    "            data_dict[node_name] = {}\n",
    "        if itemdata['itemoid'] not in data_dict[node_name].keys():\n",
    "            data_dict[node_name][itemdata['itemoid']] = []\n",
    "        try:\n",
    "            data_dict[node_name][itemdata['itemoid']].append(itemdata['value'])\n",
    "        except:\n",
    "            data_dict[node_name][itemdata['itemoid']].append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRINT DATA FILES\n"
     ]
    }
   ],
   "source": [
    "######PRINT DATA FILES######\n",
    "print('PRINT DATA FILES')\n",
    "for node_type in data_dict:\n",
    "    df = pd.DataFrame()\n",
    "    for node_key in data_dict[node_type]:\n",
    "        df[node_key] = data_dict[node_type][node_key]\n",
    "    file_name = auth['OUTPUT_FOLDER'] + node_type + \".tsv\"\n",
    "    if not os.path.exists(auth['OUTPUT_FOLDER']):\n",
    "        os.mkdir(auth['OUTPUT_FOLDER'])\n",
    "    df.to_csv(file_name, sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATE DATA FILES\n",
      "Data node SURVIVAL is not in the dataset\n",
      "Data node SURGERY_SUPPLEMENT is not in the dataset\n",
      "Data node OFF_STUDY is not in the dataset\n",
      "Data node ADVERSE_EVENTS is not in the dataset\n",
      "Data node FormOID is not in the dataset\n",
      "Data node FILE is not in the dataset\n",
      "Data node SITE is not in the dataset\n",
      "Data node PI_SIGNOFF is not in the dataset\n",
      "Data node RADIATION_SUPPLEMENT is not in the dataset\n",
      "Data node PHYSICAL_EXAM_SCREENING is not in the dataset\n",
      "Data node CLINICALTRIAL is not in the dataset\n",
      "Property LABORATORY.CRSE_NUM is not in the dataset\n",
      "Property LABORATORY.CRSE_DAY_NUM is not in the dataset\n",
      "Property LABORATORY.COMMENTS_HDR is not in the dataset\n",
      "Property PRIOR_THERAPY_SUPPLEMENT.TX_STT_DT is not in the dataset\n",
      "Property PRIOR_THERAPY_SUPPLEMENT.STOP_DT is not in the dataset\n",
      "Property PRIOR_THERAPY_SUPPLEMENT.COMMENTS_HDR is not in the dataset\n",
      "Property CONCOMITANT_MEASURES_MEDICATIONS.CRSE_NUM is not in the dataset\n",
      "Property CONCOMITANT_MEASURES_MEDICATIONS.CRSE_DAY_NUM is not in the dataset\n",
      "Property CONCOMITANT_MEASURES_MEDICATIONS.COMMENTS_HDR is not in the dataset\n",
      "Property MEDICAL_HISTORY.COMMENTS_HDR is not in the dataset\n",
      "Property STORAGE_2.COMMENTS_HDR is not in the dataset\n",
      "Property ENROLLMENT.ICF_SIG_DT is not in the dataset\n",
      "Property ENROLLMENT.COMMENTS_HDR is not in the dataset\n",
      "Property SOMATIC_VARIANT.SOMATIC_VAR_PTHGNC_CAT is not in the dataset\n",
      "Property SOMATIC_VARIANT.COMMENTS_HDR is not in the dataset\n",
      "Property FOLLOW_UP.COMMENTS_HDR is not in the dataset\n",
      "Property BASELINE_MEDICAL_HISTORY_2.COMMENTS_HDR is not in the dataset\n",
      "Property STORAGE.COMMENTS_HDR is not in the dataset\n",
      "Property CANCER_HISTORY.COMMENTS_HDR is not in the dataset\n",
      "Property SUBJECT.EVAL_DT_ENRL is not in the dataset\n",
      "Property SUBJECT.HDR1 is not in the dataset\n",
      "Property SUBJECT.REG_INST_ID_CD is not in the dataset\n",
      "Property SUBJECT.HDR2 is not in the dataset\n",
      "Property GERMLINE_VARIANT.COMMENTS_HDR is not in the dataset\n",
      "Property FOLLOW_UP_THERAPY.COMMENTS_HDR is not in the dataset\n",
      "Property PRIOR_RADIATION_SUPPLEMENT.START_DT is not in the dataset\n",
      "Property PRIOR_RADIATION_SUPPLEMENT.STOP_DT is not in the dataset\n",
      "Property PRIOR_RADIATION_SUPPLEMENT.COMMENTS_HDR is not in the dataset\n",
      "Property PRIOR_SURGERY_SUPPLEMENT.SURG_DT is not in the dataset\n",
      "Property PRIOR_SURGERY_SUPPLEMENT.COMMENTS_HDR is not in the dataset\n"
     ]
    }
   ],
   "source": [
    "######VALIDATE DATA FILES######\n",
    "print('VALIDATE DATA FILES')\n",
    "with open(auth['NODE_FILE']) as f:\n",
    "    model = yaml.load(f, Loader = yaml.FullLoader)\n",
    "for node in model['Nodes']:\n",
    "    if node not in data_dict.keys():\n",
    "        print(f'Data node {node} is not in the dataset')\n",
    "\n",
    "for node in model['Nodes']:\n",
    "    if node in data_dict.keys():\n",
    "        for prop in model['Nodes'][node]['Props']:\n",
    "            prop_name = node + '.' +  prop\n",
    "            if prop_name not in data_dict[node].keys():\n",
    "                print(f'Property {prop_name} is not in the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.852,
   "position": {
    "height": "40px",
    "left": "1522px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
